# VR we are! (CLI)

Fast, cross-platform **video â†’ stereoscopic SBS** converter powered by **Depth Anything V2**.
Built for batch work, tuned for GPUs, and designed with a **multi-stage**, **multi-threaded** pipeline that keeps your CPU, GPU and I/O busy.



## âœ¨ Features

* **Video â†’ SBS video**, **Folder with frames â†’ SBS images**, **Image â†’ Image (i2i)**
* **Presets** (minimum / balance / max_quality) for speed/quality/VRAM/RAM targets
* **CUDA + NVENC** support (auto-detects and switches when possible)
* **Pipeline parallelism** with queues: feeder â†’ preprocess â†’ GPU â†’ convert â†’ save
* Depth via **Depth Anything V2 (Small/Base/Large)**
* **Debugging**: Queue/Memory Monitor and Summary Report
* Single-file **installer** (`setup_env.py`) to pull PyTorch/FFmpeg deps



## ðŸ”— Related project (direct "relative")

This CLI grew out of the ComfyUI project:

* **VR we are! (ComfyUI nodes)** â€“ stereoscopic nodes & docs
  GitHub: [https://github.com/FortunaCournot/comfyui_stereoscopic](https://github.com/FortunaCournot/comfyui_stereoscopic)

Huge thanks to **Fortuna** (author of nodes/docs) and the ComfyUI community.

## Installation

> Tested with **Python 3.12**.

1. **Install Python 3.12**
   [https://www.python.org/downloads/](https://www.python.org/downloads/)

2. **Get the sources**

   * Clone the repo: `git clone https://github.com/Iablunoshka/VR-we-are-CLI`
     or unzip a release to a folder.

3. **Create & activate venv**

Creation venv
```bash
python -m venv venv
```
Activating venv
```bash
# Windows
venv\Scripts\activate
```
or
```bash
# Linux
source venv/bin/activate
```

4. **Run the bootstrapper**

```bash
python setup_env.py
```

This will:

* install packages from `requirements.txt`,
* detect **CUDA** and install a matching **PyTorch** wheel (falls back to CPU build),
* check **FFmpeg** availability (prints tips if missing).

> FFmpeg must be in `PATH`.
> Windows (Chocolatey): `choco install ffmpeg`
> Ubuntu/Debian: `sudo apt install ffmpeg`



## ðŸš€ Quick start

### Video â†’ SBS video

```bash
python main.py -i input.mp4 -o output_sbs.mp4 --preset balance
```

### Folder of frames â†’ SBS PNGs

```bash
python main.py -i ./frames -o ./out --input-type folder --preset balance
```

### Single image (i2i)

One image
```bash
python main.py -i image.png -o image_sbs.png --input-type i2i
```
Several images
```bash
python main.py -i ./Images -o ./out --input-type i2i
```

### Debug mode

To see detailed performance stats and system info, add `-d`:
```bash
python main.py -i input.mp4 -o output_sbs.mp4 --preset balance -d
```



## âš¡ Performance Presets (Full HD, Depth-Anything-V2)
Benchmarks measured on **AMD Ryzen 7 7700X + NVIDIA GeForce RTX 5090 + 32 GB DDR5**  
*(Windows 10, CUDA 12, Python 3.12)*  

###  Presets - Folder Mode (Full HD)

| Preset | Target VRAM | Model | Batch | Feeders | Preprocess | Processors | Savers | Queues (r/in/p/s) | RAM Usage (avg/max GB) | FPS | Notes |
|:-------|:-------------|:-------|:-------|:---------|:------------|:------------|:--------|:------------------|:------------------------|:------|:------|
| **Minimum** | 4 GB | Depth-Anything-V2-Small-hf | 4 | 1 | 1 | 4 | 3 | 8 | 4,3 / 4,8 | **21.9 FPS** | Optimized for low-VRAM/RAM system |
| **Balance** | 8 GB | Depth-Anything-V2-Base-hf | 5 | 1 | 2 | 8 | 4 | 16 | 7,0 / 7,7 | **22.2 FPS** | Best overall performance |
| **Max Quality** | 12 GB | Depth-Anything-V2-Large-hf | 6 | 1 | 2 | 4 | 2 | 16 | 5,0/ 5,8 | **16.7 FPS** | Highest depth accuracy, GPU-bound |

###  Presets - Video Mode (Full HD)
| Preset | Target VRAM | Model | Batch | Feeders | Preprocess | Processors | Savers | Queues (r/in/p/s) | RAM Usage (avg/max GB) | FPS | Notes |
|:-------|:-------------|:-------|:-------|:---------|:------------|:------------|:--------|:------------------|:------------------------|:------|:------|
| **Minimum** | 4 GB | Depth-Anything-V2-Small-hf | 3 | 1 | 1 | 4 | 1 | 6 | 4,4 / 5,0 | **19.8 FPS** | Optimized for low-VRAM/RAM system |
| **Balance** | 8 GB | Depth-Anything-V2-Base-hf | 5 | 1 | 2 | 8 | 1 | 16 | 8,4 / 9,8 | **21.8 FPS** | Best overall performance |
| **Max Quality** | 12 GB | Depth-Anything-V2-Large-hf | 6 | 1 | 1 | 3 | 1 | 16 | 5,2/ 5,7 | **16.5 FPS** | Highest depth accuracy, GPU-bound |

---

#### Linux Performance

- On **Linux** (tested on *Ubuntu 24.04 + CUDA 12*), performance is **significantly higher** compared to Windows.  
- In some cases, the save queue may fill faster - if RAM usage increases over time, raise the number of savers (`--savers +1â€¦2`).  
- For best stability and throughput, **Linux is the recommended platform**.

#### Windows Performance

- After several hours of system uptime, performance may drop by **â‰ˆ25 %**, likely due to Windows scheduler or GPU driver throttling (not related to the script).  
- To ensure consistent results, **reboot before long renders or benchmarking**.  
- The presets above were benchmarked on **Windows 10**, so FPS values reflect typical Windows performance.


## Project structure

```
â”œâ”€ main.py               # CLI entrypoint (initialization, CLI-interface, launch)
â”œâ”€ pipeline_core.py      # Worker threads (feeder â†’ preprocess â†’ GPU â†’ process â†’ save)
â”œâ”€ depthestimator.py     # Depth Anything V2 (HF Transformers + PyTorch)
â”œâ”€ converter.py          # SBS image conversion (Numba + OpenCV)
â”œâ”€ utils.py              # NVENC detect, presets merge, system info, debug report
â”œâ”€ monitor.py            # Queue/Memory monitors + plots
â”œâ”€ presets.json          # Ready presets (video/folder)
â”œâ”€ setup_env.py          # Bootstrap PyTorch/FFmpeg and requirements
â”œâ”€ requirements.txt
â””â”€ README.md
```

## Credits

* **Fortuna** - original ComfyUI nodes, docs, and project leadership
* **Sam Seen** - ComfyUI_SSStereoscope inspiration
* Community testers and artists who shared feedback and examples



## ðŸ’¬ Contact

* GitHub Issues: [https://github.com/Iablunoshka/VR-we-are-CLI/issues](https://github.com/Iablunoshka/VR-we-are-CLI/issues)
* Discord: [Activation Link](https://discord.gg/ZegT6Cc8FG)


